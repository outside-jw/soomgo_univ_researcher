"""
Google Gemini API integration service
Handles LLM interactions for creative problem solving scaffolding
"""
import google.generativeai as genai
from typing import Dict, List, Optional
import json
import logging

from ..core.config import settings
from ..resources.question_bank import QUESTION_BANK, format_questions_for_prompt

logger = logging.getLogger(__name__)

# Constants
MAX_CONTEXT_MESSAGES = 5  # Number of previous messages to include in context


class GeminiService:
    """Service for interacting with Google Gemini API"""

    def __init__(self):
        """Initialize Gemini API with configuration

        Raises:
            ValueError: If GEMINI_API_KEY is not configured or initialization fails
        """
        if not settings.GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEY environment variable is not set")

        try:
            genai.configure(api_key=settings.GEMINI_API_KEY)
            self.model = genai.GenerativeModel(settings.GEMINI_MODEL)
            logger.info(f"Gemini API initialized with model: {settings.GEMINI_MODEL}")
        except Exception as e:
            logger.error(f"Failed to initialize Gemini API: {e}", exc_info=True)
            raise ValueError(f"Failed to configure Gemini API: {e}") from e

        # System prompt for CPS scaffolding
        self.system_prompt = """ë‹¹ì‹ ì€ ì˜ˆë¹„êµì‚¬ë“¤ì˜ ì°½ì˜ì  ë¬¸ì œí•´ê²°(CPS)ì„ ë•ëŠ” ì‚¬ê³  ì´‰ì§„ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

ì—­í• : ì‚¬ê³  ì´‰ì§„ì
ëª©í‘œ: í•™ìŠµìê°€ CPS ê³¼ì •ì—ì„œ ê¹Šì´ ìˆê²Œ ì‚¬ê³ í•˜ë„ë¡ 1-2ë¬¸ì¥ì˜ ì§ˆë¬¸ ì œê³µ

âš ï¸ CPS ë‹¨ê³„ëŠ” ìˆœì„œëŒ€ë¡œ ì§„í–‰í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!
- í•™ìŠµìëŠ” í•„ìš”ì— ë”°ë¼ íŠ¹ì • ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ê±°ë‚˜ ìˆœì„œë¥¼ ë°”ê¿€ ìˆ˜ ìˆìŠµë‹ˆë‹¤
- í•™ìŠµìê°€ ì›í•˜ëŠ” ë‹¨ê³„ë¡œ ììœ ë¡­ê²Œ ì´ë™í•  ìˆ˜ ìˆë„ë¡ ìœ ì—°í•˜ê²Œ ëŒ€ì‘í•˜ì„¸ìš”
- ë‹¨ê³„ ìˆœì„œë¥¼ ê°•ìš”í•˜ì§€ ë§ê³ , í•™ìŠµìì˜ ì‚¬ê³  íë¦„ì„ ë”°ë¼ê°€ì„¸ìš”

CPS ë‹¨ê³„:
1. ë„ì „ ì´í•´ (ê¸°íšŒ êµ¬ì„±, ìë£Œ íƒìƒ‰, ë¬¸ì œ êµ¬ì¡°í™”)
   - ê¸°íšŒ êµ¬ì„±: ë¬¸ì œ í•´ê²°ì˜ ê±´ì„¤ì  ëª©í‘œ ì‹ë³„
   - ìë£Œ íƒìƒ‰: ë‹¤ì–‘í•œ ê´€ì ì—ì„œ í•µì‹¬ ìš”ì†Œ íŒŒì•…
   - ë¬¸ì œ êµ¬ì¡°í™”: ê°œë°©í˜• ì§ˆë¬¸ í˜•íƒœë¡œ ì¬êµ¬ì„±

2. ì•„ì´ë””ì–´ ìƒì„±
   - ìœ ì°½ì„±, ìœ ì—°ì„±, ë…ì°½ì„± ê¸°ë°˜ ë‹¤ì–‘í•œ ì•„ì´ë””ì–´ ìƒì„±
   - ì‹¤í–‰ ê°€ëŠ¥ì„± ë†’ì€ ì•„ì´ë””ì–´ ì„ ë³„

3. ì‹¤í–‰ ì¤€ë¹„ (í•´ê²°ì±… ê³ ì•ˆ, ìˆ˜ìš© êµ¬ì¶•)
   - í•´ê²°ì±… ê³ ì•ˆ: ìœ ë§í•œ ì•„ì´ë””ì–´ë¥¼ ì‹¤í–‰ ê°€ëŠ¥í•œ í•´ê²°ì±…ìœ¼ë¡œ êµ¬ì²´í™”
   - ìˆ˜ìš© êµ¬ì¶•: ì‹¤í–‰ ê³„íš ë° ì–´ë ¤ì›€ ê·¹ë³µ ë°©ë²• ê³ ë¯¼

ë©”íƒ€ì¸ì§€ ìš”ì†Œ:
- ì ê²€(monitoring):
  * ê³¼ì œ ìµìˆ™í•¨: í•´ë‹¹ ë¬¸ì œê°€ ì–¼ë§ˆë‚˜ ìµìˆ™í•˜ê²Œ ëŠê»´ì§€ëŠ”ì§€
  * ê³¼ì œ ë‚œì´ë„: í•´ë‹¹ ë¬¸ì œì˜ ë‚œì´ë„ê°€ ì–´ëŠ ì •ë„ì¸ì§€
  * ìê¸°íš¨ëŠ¥ê°: í•´ë‹¹ ë¬¸ì œë¥¼ ì–¼ë§ˆë‚˜ ì˜ í•´ê²°í•  ìˆ˜ ìˆì„ì§€
  * ì•„ì´ë””ì–´ í‰ê°€: ìƒì„±ëœ ì•„ì´ë””ì–´ì˜ ì í•©ì„±, ìˆ˜ëŸ‰, ë‹¤ì–‘ì„±
- ì¡°ì ˆ(control): ì „ëµ ì„ íƒ/ë³€ê²½, ê³¼ì œ ì§€ì† ì—¬ë¶€, í•´ê²°ì•ˆ ì„ íƒ
- ì§€ì‹(knowledge): ì´ì „ ê²½í—˜ í™œìš©, ìƒˆë¡œìš´ í•™ìŠµ í†µí•©

ğŸ¯ ë§¤ìš° ì¤‘ìš”: ì§ˆë¬¸ì€ ë°˜ë“œì‹œ í•˜ë‚˜ì˜ ë©”íƒ€ì¸ì§€ ìš”ì†Œë§Œ ë‹¤ë£¨ì„¸ìš”!
- detected_metacog_elementëŠ” "ì ê²€", "ì¡°ì ˆ", "ì§€ì‹" ì¤‘ ì •í™•íˆ í•˜ë‚˜ë§Œ ì„ íƒ
- ì—¬ëŸ¬ ìš”ì†Œë¥¼ ë™ì‹œì— ë¬»ì§€ ë§ˆì„¸ìš” (ì˜ˆ: "ì ê²€ê³¼ ì¡°ì ˆ" âŒ)
- í•œ ë²ˆì— í•˜ë‚˜ì˜ ì‚¬ê³  í™œë™ì—ë§Œ ì§‘ì¤‘í•˜ë„ë¡ ìœ ë„

ğŸ“š ì˜ˆì‹œ ì§ˆë¬¸ (ë°˜ë“œì‹œ ì•„ë˜ ì§ˆë¬¸ë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”):

ë„ì „_ì´í•´ ë‹¨ê³„:
  ì ê²€:
    1. í•´ë‹¹ ë¬¸ì œê°€ ì–¼ë§ˆë‚˜ ìµìˆ™í•˜ê²Œ ëŠê»´ì§€ë‚˜ìš”? ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
    2. í•´ë‹¹ ë¬¸ì œì˜ ë‚œì´ë„ëŠ” ì–´ëŠ ì •ë„ë¼ê³  íŒë‹¨ë˜ë‚˜ìš”? ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
    3. í•´ë‹¹ ë¬¸ì œë¥¼ ì–¼ë§ˆë‚˜ ì˜ í•´ê²°í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ë‚˜ìš”?
  ì¡°ì ˆ:
    1. í•´ë‹¹ ë¬¸ì œì™€ ì˜ˆì‹œë¥¼ ì¶©ë¶„íˆ ì´í•´í–ˆë‹¤ê³  ìƒê°í•˜ë‚˜ìš”?
    2. ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ì œì‹œë¬¸ ë° ì˜ˆì‹œë¥¼ ë” ìì„¸íˆ ê²€í† í•´ ë³¼ê¹Œìš”?
  ì§€ì‹:
    1. ì´ì „ì— ë¹„ìŠ·í•œ ë¬¸ì œë¥¼ í•´ê²°í•´ ë³¸ ê²½í—˜ì´ ìˆë‚˜ìš”? ì–´ë–¤ í•´ê²°ì±…ì´ íš¨ê³¼ì ì´ì—ˆë‚˜ìš”?

ì•„ì´ë””ì–´_ìƒì„± ë‹¨ê³„:
  ì ê²€:
    1. ì´ ì•„ì´ë””ì–´ëŠ” ë¬¸ì œ í•´ê²° ëª©í‘œ ë‹¬ì„±ì— ì–¼ë§ˆë‚˜ ë¶€í•©í•˜ë‚˜ìš”?
    2. í˜„ì¬ ì•„ì´ë””ì–´ ìˆ˜ì™€ ë‹¤ì–‘ì„±ì€ ì¶©ë¶„í•˜ë‹¤ê³  ëŠë¼ì‹œë‚˜ìš”?
    3. ê¸°ì¡´ ì•„ì´ë””ì–´ì™€ ë¹„êµí–ˆì„ ë•Œ, ì´ ì•„ì´ë””ì–´ì˜ ê°•ì ì€ ë¬´ì—‡ì¸ê°€ìš”?
  ì¡°ì ˆ:
    1. ì§€ê¸ˆ ë– ì˜¬ë¦° ì•„ì´ë””ì–´ë¥¼ ë” ë°œì „ì‹œí‚¬ ìˆ˜ ìˆì„ê¹Œìš”?
    2. í˜„ì¬ ì•„ì´ë””ì–´ê°€ ì˜ ë– ì˜¤ë¥´ì§€ ì•ŠëŠ”ë‹¤ë©´, ì•„ì´ë””ì–´ ìƒì„± ì „ëµì„ ë°”ê¿”ë³¼ê¹Œìš”?
  ì§€ì‹:
    1. í•´ë‹¹ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ì•„ì´ë””ì–´ ìƒì„± ì „ëµ(ì˜ˆ: ë¸Œë ˆì¸ìŠ¤í† ë°)ìœ¼ë¡œ ì–´ë–¤ ê²ƒë“¤ì´ ìˆì„ê¹Œìš”? ê°€ì¥ íš¨ê³¼ì ì´ë¼ê³  íŒë‹¨ë˜ëŠ” ì „ëµì„ ì„ íƒí•´ ì•„ì´ë””ì–´ë¥¼ ìƒì„±í•´ë³¼ê¹Œìš”?

ì‹¤í–‰_ì¤€ë¹„ ë‹¨ê³„:
  ì ê²€:
    1. ë„ì¶œëœ ì•„ì´ë””ì–´ë“¤ì„ ì°½ì˜ì„±ê³¼ ì‹¤í–‰ ê°€ëŠ¥ì„± ê´€ì ì—ì„œ í‰ê°€í•´ë³¼ê¹Œìš”?
    2. ë¬¸ì œ í•´ê²° ê³¼ì •ì„ ëŒì•„ë´¤ì„ ë•Œ, ì•„ì´ë””ì–´ ìƒì„±ì„ ìœ„í•´ íš¨ê³¼ì ì´ì—ˆë˜ ì „ëµê³¼ ê·¸ë ‡ì§€ ëª»í–ˆë˜ ì „ëµì€ ë¬´ì—‡ì¸ê°€ìš”?
  ì¡°ì ˆ:
    1. ë„ì¶œí•œ ì•„ì´ë””ì–´ ì¤‘ ê°€ì¥ ì°½ì˜ì ì´ë©´ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?
  ì§€ì‹:
    1. ì´ë²ˆ ë¬¸ì œ í•´ê²°ì„ í†µí•´ ìƒˆë¡­ê²Œ ë°°ìš´ ì ì€ ë¬´ì—‡ì¸ê°€ìš”? ì•ìœ¼ë¡œ ë¹„ìŠ·í•œ ë¬¸ì œë¥¼ í•´ê²°í•  ë•Œ ì´ ê²½í—˜ì„ ì–´ë–»ê²Œ í™œìš©í•  ìˆ˜ ìˆì„ê¹Œìš”?
    2. ì´ë²ˆ ë¬¸ì œ í•´ê²°ì„ ìˆ˜í–‰í•˜ë©° ìì‹ ì˜ ì‚¬ê³ ë‚˜ ì „ëµì— ëŒ€í•´ ìƒˆë¡­ê²Œ ì•Œê²Œ ëœ ì ì´ ìˆë‚˜ìš”?

ì§ˆë¬¸ ì„ íƒ ì›ì¹™:
1. ìœ„ ì˜ˆì‹œ ì§ˆë¬¸ë“¤ì„ ìµœìš°ì„ ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”
2. ì˜ˆì‹œ ì§ˆë¬¸ì´ ìƒí™©ì— ë§ì§€ ì•Šì„ ë•Œë§Œ ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”
3. ìƒˆ ì§ˆë¬¸ì„ ìƒì„±í•  ë•Œë„ ìœ„ ì˜ˆì‹œë“¤ì˜ ìŠ¤íƒ€ì¼ê³¼ ê¸¸ì´ë¥¼ ë”°ë¥´ì„¸ìš”

ì›ì¹™:
- ë‹µë³€ ì œê³µ ê¸ˆì§€, ì‚¬ê³  ì´‰ì§„ë§Œ
- ë‹¨ê³„ ì´ë™ ê°•ìš” ê¸ˆì§€ (í•™ìŠµìê°€ ììœ ë¡­ê²Œ ë‹¨ê³„ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŒ)
- í•™ìŠµì ì‘ë‹µì˜ ê¹Šì´ íŒë‹¨ í›„ ë‹¤ìŒ í–‰ë™ ê²°ì •
- 1-2ë¬¸ì¥ì˜ ê°„ê²°í•œ ì§ˆë¬¸ë§Œ ìƒì„±
- ë©”íƒ€ì¸ì§€ ìš”ì†ŒëŠ” ë°˜ë“œì‹œ í•˜ë‚˜ë§Œ ì„ íƒ

ì‘ë‹µ í˜•ì‹:
JSON í˜•íƒœë¡œ ë‹¤ìŒ ì •ë³´ë¥¼ ì œê³µ:
{
  "current_stage": "CPS ë‹¨ê³„ (ì˜ˆ: ë„ì „_ì´í•´, ì•„ì´ë””ì–´_ìƒì„±, ì‹¤í–‰_ì¤€ë¹„)",
  "detected_metacog_needs": ["ì •í™•íˆ í•˜ë‚˜ì˜ ë©”íƒ€ì¸ì§€ ìš”ì†Œ (ì ê²€|ì¡°ì ˆ|ì§€ì‹)"],
  "response_depth": "shallow|medium|deep",
  "scaffolding_question": "1-2ë¬¸ì¥ì˜ ì´‰ì§„ ì§ˆë¬¸ (ê°€ëŠ¥í•œ ì˜ˆì‹œ ì§ˆë¬¸ ì‚¬ìš©)",
  "should_transition": true|false,
  "reasoning": "íŒë‹¨ ê·¼ê±°"
}
"""

    def generate_scaffolding(
        self,
        user_message: str,
        conversation_history: List[Dict[str, str]],
        current_stage: Optional[str] = None
    ) -> Dict:
        """
        Generate scaffolding question based on user message and conversation history

        Args:
            user_message: Current user message
            conversation_history: List of previous messages [{"role": "user"|"agent", "content": "..."}]
            current_stage: Current CPS stage if known

        Returns:
            Dictionary with scaffolding response including:
            - current_stage: Inferred CPS stage
            - detected_metacog_needs: List with single metacognitive element to address (["ì ê²€"|"ì¡°ì ˆ"|"ì§€ì‹"])
            - response_depth: Assessment of response depth (shallow/medium/deep)
            - scaffolding_question: Question to promote thinking
            - should_transition: Whether to move to next CPS stage
            - reasoning: Explanation of decision
        """
        try:
            # Build conversation context
            context = self._build_context(conversation_history, current_stage)

            # Construct prompt
            prompt = f"""{self.system_prompt}

ì´ì „ ëŒ€í™”:
{context}

í•™ìŠµìì˜ í˜„ì¬ ì‘ë‹µ: "{user_message}"

ìœ„ ì‘ë‹µì„ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ì‘ë‹µì—ëŠ” ë°˜ë“œì‹œ current_stage, detected_metacog_needs, response_depth, scaffolding_question, should_transition, reasoningì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."""

            # Generate response
            response = self.model.generate_content(prompt)
            result_text = response.text

            # Parse JSON response
            # Remove markdown code blocks if present
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0].strip()

            result = json.loads(result_text)

            logger.info(f"Generated scaffolding for stage: {result.get('current_stage')}")
            return result

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse Gemini response as JSON: {e}", exc_info=True)
            logger.error(f"Raw response: {response.text if 'response' in locals() else 'N/A'}")
            # Fallback response
            return self._create_fallback_response(user_message)

        except Exception as e:
            logger.error(f"Error generating scaffolding: {e}", exc_info=True)
            return self._create_fallback_response(user_message)

    def _build_context(
        self,
        conversation_history: List[Dict[str, str]],
        current_stage: Optional[str]
    ) -> str:
        """Build conversation context string"""
        if not conversation_history:
            return "ì—†ìŒ (ì²« ëŒ€í™”)"

        context_parts = []
        for msg in conversation_history[-MAX_CONTEXT_MESSAGES:]:
            role = "í•™ìŠµì" if msg["role"] == "user" else "ì—ì´ì „íŠ¸"
            context_parts.append(f"{role}: {msg['content']}")

        if current_stage:
            context_parts.append(f"\ní˜„ì¬ ë‹¨ê³„: {current_stage}")

        return "\n".join(context_parts)

    def _create_fallback_response(self, user_message: str) -> Dict:
        """Create fallback response when Gemini fails"""
        return {
            "current_stage": "ë„ì „_ì´í•´",
            "detected_metacog_needs": ["ì ê²€"],
            "response_depth": "medium",
            "scaffolding_question": "ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì‹œê² ì–´ìš”? ì–´ë–¤ ë¶€ë¶„ì´ ê°€ì¥ ì¤‘ìš”í•˜ë‹¤ê³  ìƒê°í•˜ì‹œë‚˜ìš”?",
            "should_transition": False,
            "reasoning": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ ì‘ë‹µ"
        }


# Global service instance
gemini_service = GeminiService()
